{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "05ve22CaWR6a",
        "outputId": "658b3807-b96d-46d9-c700-9a22b1162148"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6mJov0OuW-Ky"
      },
      "outputs": [],
      "source": [
        "!unzip -q /content/drive/MyDrive/datasets/GP-total-finetune.zip -d ./\n",
        "#!unzip -q /content/drive/MyDrive/datasets/GP-180-roboflow-eval.zip -d ./\n",
        "!unzip -q /content/drive/MyDrive/datasets/GP-180-saurabh-eval.zip -d ./\n",
        "!ln -s /content/drive/MyDrive/datasets/GP-180"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v2JUJbCBzjp7"
      },
      "outputs": [],
      "source": [
        "!ln -s /content/drive/MyDrive/datasets/Grozi-3.2k-mine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0C7n4RdDMz98"
      },
      "outputs": [],
      "source": [
        "!unzip -q /content/drive/MyDrive/datasets/Grozi3.2k_Grocery_products.zip -d ./"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DBIoe_tHTQgV",
        "outputId": "629613e8-f893-4f2f-930a-3808024590ad"
      },
      "outputs": [],
      "source": [
        "%%shell\n",
        "\n",
        "pip install cython\n",
        "# Install pycocotools, the version by default in Colab\n",
        "# has a bug fixed in https://github.com/cocodataset/cocoapi/pull/354\n",
        "pip install -U 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YG0YyvvuYWBe",
        "outputId": "2a47ced5-b275-4d57-8795-f4b99225d8a6"
      },
      "outputs": [],
      "source": [
        "%%shell\n",
        "\n",
        "# Download TorchVision repo to use some files from\n",
        "# references/detection\n",
        "git clone https://github.com/pytorch/vision.git\n",
        "cd vision\n",
        "git checkout v0.3.0\n",
        "\n",
        "cp references/detection/utils.py ../\n",
        "cp references/detection/transforms.py ../\n",
        "cp references/detection/coco_eval.py ../\n",
        "cp references/detection/engine.py ../\n",
        "cp references/detection/coco_utils.py ../"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b3ov2zc0YFPv"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.ops as ops\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "from torchvision.models.detection import faster_rcnn, rpn, FasterRCNN, backbone_utils,mask_rcnn\n",
        "from torchvision import models,transforms\n",
        "\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "import seaborn as sbn\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.cluster import DBSCAN,OPTICS\n",
        "\n",
        "import os\n",
        "from engine import train_one_epoch, evaluate\n",
        "import utils\n",
        "import transforms as T\n",
        "import math\n",
        "from tqdm import tqdm\n",
        "from copy import deepcopy\n",
        "import numpy as np\n",
        "from time import time\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0nHnEGrvdzlF"
      },
      "outputs": [],
      "source": [
        "epsilon = 1e-7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WkIQL9evue49"
      },
      "outputs": [],
      "source": [
        "CPU = torch.device('cpu')\n",
        "GPU = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mTgWtixZTs3X"
      },
      "outputs": [],
      "source": [
        "grozi_root = \"/content/Grozi-3.2k-mine\"\n",
        "\n",
        "@torch.no_grad()\n",
        "def validate_voc_format(model,eval_dataset,top_k = 1,plot = False,apply_brisk = False,threshold = 0.20):\n",
        "    print(\"Starting evaluation .....\\n\")\n",
        "    model.eval()\n",
        "    stats = []\n",
        "    predictions = []\n",
        "    ignoreable = []\n",
        "    wrong_recogs = []\n",
        "    inference_times = []\n",
        "    for idx in tqdm(range(len(eval_dataset))):\n",
        "        #print(\"\\nprocessing item\",idx)\n",
        "        img_ts,target_ts = eval_dataset[idx]\n",
        "        img_ts = img_ts.to(GPU)\n",
        "\n",
        "        labels = target_ts[\"annots\"]\n",
        "        labels = [os.path.join(grozi_root,x[:-4]) for x in labels ]\n",
        "        #print(labels)\n",
        "        #labels = target_ts[\"labels\"]\n",
        "        \n",
        "        uniq_labels = set(labels)\n",
        "        pred_uniq_labels = set([])\n",
        "\n",
        "        prediction_boxes = model([img_ts])[0][\"boxes\"].to(CPU)\n",
        "        n_boxes_pred = prediction_boxes.shape[0]\n",
        "        \n",
        "        iou_matrix = ops.box_iou(prediction_boxes,target_ts[\"boxes\"])\n",
        "        best_ious, best_iou_indices = iou_matrix.max(1)\n",
        "\n",
        "        correct = torch.zeros(n_boxes_pred)\n",
        "        marker = torch.zeros(n_boxes_pred)\n",
        "        \n",
        "        ignore = 0\n",
        "        \n",
        "        for i in range(len(best_ious)):     # processing one image at a time\n",
        "            \n",
        "            tag = labels[best_iou_indices[i]]\n",
        "            tag = tag[tag.rfind(\"/\") + 1:]\n",
        "            if tag == \"-1\":\n",
        "                best_ious[i] = 0.07\n",
        "                #print(\"-1 detected\")\n",
        "\n",
        "            if best_ious[i] <= 0.08:\n",
        "                ignore +=1\n",
        "\n",
        "            if best_ious[i] >= threshold:\n",
        "                \n",
        "                x1,y1,x2,y2 = prediction_boxes[i]\n",
        "                x1,y1,x2,y2 = int(x1),int(y1),int(x2),int(y2)\n",
        "                \n",
        "                cropped = img_ts[:,y1:y2,x1:x2]\n",
        "                pcls = yield_top_k_matches(cropped,k = top_k,apply_BRISK = apply_brisk)\n",
        "                \n",
        "                if labels[best_iou_indices[i]] in pcls:\n",
        "                    correct[i] = 1\n",
        "                    marker[i] = 1\n",
        "                    pred_uniq_labels.add(labels[best_iou_indices[i]])\n",
        "                else:\n",
        "                    wrong_recogs.append((labels[best_iou_indices[i]],cropped,pcls[0]))\n",
        "                    marker[i] = -1\n",
        "\n",
        "        \n",
        "        ignoreable.append(ignore)\n",
        "        stats.append((correct,\n",
        "                      best_ious,\n",
        "                      len(labels),\n",
        "                      len(uniq_labels),\n",
        "                      len(pred_uniq_labels),\n",
        "                      marker))\n",
        "        predictions.append(prediction_boxes)\n",
        "\n",
        "    AP = 0\n",
        "    AR = 0\n",
        "    aPR = 0\n",
        "    for (stat_img,ignored) in zip(stats,ignoreable):\n",
        "        if len(stat_img[0]):\n",
        "            AR += stat_img[0].sum()/(stat_img[2] + epsilon)\n",
        "            AP += stat_img[0].sum()/( len(stat_img[0]) - ignored + epsilon)\n",
        "            aPR += stat_img[4]/(stat_img[3] + epsilon)\n",
        "\n",
        "    print(\"\\nlen of stats\",len(stats))\n",
        "    AP = AP/len(stats)\n",
        "    AR = AR/len(stats)\n",
        "    aPR = aPR/len(stats)\n",
        "    Fscore = (2 * AP * AR) / (AP + AR + epsilon) \n",
        "    \n",
        "    print(\"[M.George] mAP @{0}:      {1:.3f}\".format(threshold,AP))\n",
        "    print(\"[--------] AR @{0}:       {1:.3f}\".format(threshold,AR))\n",
        "    print(\"[--------] AF-score @{0}: {1:.3f}\".format(threshold,Fscore))\n",
        "    print(\"[M.George] PR @{0}:       {1:.3f}\".format(threshold,aPR))\n",
        "    return predictions,stats,wrong_recogs,AP\n",
        "\n",
        "@torch.no_grad()\n",
        "def validate_ISI_format(model,eval_dataset,top_k = 1,plot = False,apply_brisk = False):\n",
        "    #print(\"\\nStarting evaluation .....\\n\")\n",
        "    model.eval()\n",
        "    \n",
        "    predictions = []\n",
        "    ignoreable = []\n",
        "    \n",
        "    Pr = []\n",
        "    Rc = []\n",
        "    Fsc = []\n",
        "    for idx in tqdm(range(len(eval_dataset))):\n",
        "        img_ts,target_ts = eval_dataset[idx]\n",
        "        img_ts = img_ts.to(GPU)\n",
        "        labels = target_ts[\"annots\"]\n",
        "        #labels = target_ts[\"labels\"]\n",
        "        prediction_boxes = model([img_ts])[0][\"boxes\"].to(CPU)\n",
        "        n_boxes_pred = prediction_boxes.shape[0]\n",
        "        TP = 0\n",
        "        FP = 0\n",
        "        for pred_box in prediction_boxes:\n",
        "            tp = 0\n",
        "            entered = 0\n",
        "            centre_pred = ((pred_box[0] + pred_box[2])/2 , (pred_box[1] + pred_box[3])/2)\n",
        "\n",
        "            for (gt_box,label) in zip(target_ts[\"boxes\"],labels):\n",
        "                X1,Y1,X2,Y2 = gt_box\n",
        "\n",
        "                if centre_pred[0] >= X1 and centre_pred[0] <= X2 and centre_pred[1] <= Y2 and centre_pred[1] >= Y1:\n",
        "                    x1,y1,x2,y2 = pred_box\n",
        "                    x1,y1,x2,y2 = int(x1),int(y1),int(x2),int(y2)\n",
        "                \n",
        "                    cropped = img_ts[:,y1:y2,x1:x2]\n",
        "                    pcls = yield_top_k_matches(cropped,k = top_k,apply_BRISK = apply_brisk)\n",
        "\n",
        "                    entered = 1\n",
        "                    if label in pcls:\n",
        "                        tp = 1\n",
        "                        break\n",
        "\n",
        "            if tp == 1:\n",
        "                TP += 1\n",
        "            elif entered == 1:\n",
        "                FP += 1\n",
        "        \n",
        "        Precision = TP/(TP + FP + epsilon)\n",
        "        Recall = TP /len(labels)\n",
        "        F_score = (2 * Precision * Recall) /(Precision + Recall + epsilon)\n",
        "\n",
        "        Pr.append(Precision)\n",
        "        Rc.append(Recall)\n",
        "        Fsc.append(F_score)\n",
        "\n",
        "    AP = sum(Pr)/len(Pr)\n",
        "    AR = sum(Rc)/len(Rc)\n",
        "    AFsc = sum(Fsc)/len(Fsc) \n",
        "    \n",
        "    print(\"\\n[ISI] Avg. Precision: {0:.3f}\".format(AP))\n",
        "    print(\"[ISI] Avg. Recall     {0:.3f}\".format(AR))\n",
        "    print(\"[ISI] Avg. F-score :  {0:.3f}\".format(AFsc))\n",
        "    return predictions\n",
        "\n",
        "def plot_img_with_boxes(image,bboxes,thickness = 2, color = (255,0,0)):\n",
        "    plt.figure(figsize = (15,13))\n",
        "    if image.shape[0] == 3:\n",
        "        image = image.permute(1,2,0).numpy()\n",
        "    for i in range(bboxes.shape[0]):\n",
        "        start_pt = (int(bboxes[i][0]),int(bboxes[i][1]))\n",
        "        end_pt = (int(bboxes[i][2]),int(bboxes[i][3]))\n",
        "        image = cv2.rectangle(image,start_pt,end_pt,color,thickness)\n",
        "    plt.imshow(image)\n",
        "    plt.show()\n",
        "\n",
        "def plot_pred_gt_side_by_side(eval_dataset,\n",
        "                              predictions,\n",
        "                              color1 = (255,0,0),\n",
        "                              color2 = (0,0,255),\n",
        "                              color3 = (0,255,0),\n",
        "                              color4 = (247, 243, 15),\n",
        "                              thickness = 2,\n",
        "                              judgements = None):\n",
        "    \n",
        "    for idx in range(len(eval_dataset)):\n",
        "        image, target = eval_dataset[idx]\n",
        "        gtboxes = target[\"boxes\"]\n",
        "        bboxes = predictions[idx]\n",
        "        image = image.permute(1,2,0).numpy()\n",
        "        image1 = image.copy()\n",
        "        image2 = image.copy()\n",
        "        \n",
        "        fig, axs = plt.subplots(1,2,figsize = (20,30),sharex = True)\n",
        "        for i in range(bboxes.shape[0]):\n",
        "            start_pt = (int(bboxes[i][0]),int(bboxes[i][1]))\n",
        "            end_pt = (int(bboxes[i][2]),int(bboxes[i][3]))\n",
        "            if judgements:\n",
        "                if judgements[idx][i] == 0:\n",
        "                    image1 = cv2.rectangle(image1,start_pt,end_pt,color3,thickness)\n",
        "                elif judgements[idx][i] == -1:\n",
        "                    image1 = cv2.rectangle(image1,start_pt,end_pt,color4,thickness)\n",
        "                else:\n",
        "                    image1 = cv2.rectangle(image1,start_pt,end_pt,color1,thickness)\n",
        "            else:\n",
        "                image1 = cv2.rectangle(image1,start_pt,end_pt,color1,thickness)\n",
        "\n",
        "        for i in range(gtboxes.shape[0]):\n",
        "            start_pt = (int(gtboxes[i][0]),int(gtboxes[i][1]))\n",
        "            end_pt = (int(gtboxes[i][2]),int(gtboxes[i][3]))\n",
        "            image2 = cv2.rectangle(image2,start_pt,end_pt,color2,thickness)\n",
        "\n",
        "        axs[0].imshow(image1)\n",
        "        axs[1].imshow(image2)\n",
        "    \n",
        "def display(image,fig_size = (10,8)):\n",
        "    if image.shape[0] == 3:\n",
        "        image = image.permute(1,2,0).numpy()\n",
        "    plt.figure(figsize = fig_size)\n",
        "    plt.imshow(image)\n",
        "    plt.show()\n",
        "\n",
        "class GroceryProducts(Dataset):\n",
        "    def __init__(self, root, transforms = None):\n",
        "        self.root = root\n",
        "        self.transforms = transforms\n",
        "        self.imgs = list(sorted(os.listdir(os.path.join(root, \"images\"))))\n",
        "        self.labels = list(sorted(os.listdir(os.path.join(root, \"annotations\"))))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        num_img = self.imgs[idx][:-4]\n",
        "        num_label = self.labels[idx][5:-4]\n",
        "        assert num_img == num_label\n",
        "\n",
        "        img_path = os.path.join(self.root, \"images\", self.imgs[idx])\n",
        "       \n",
        "        label_path = os.path.join(self.root, \"annotations\", self.labels[idx])\n",
        "        img = cv2.imread(img_path)\n",
        "        img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
        "        img = cv2.resize(img,(410,410))\n",
        "        img = img / 255.0\n",
        "        H ,W = img.shape[0], img.shape[1]\n",
        "        img = torch.from_numpy(img).float()\n",
        "        img = img.permute(2,0,1)\n",
        "        boxes = []\n",
        "        annots = []\n",
        "        \n",
        "        txt_reader = open(label_path,'r')\n",
        "        i = 0\n",
        "        for line in txt_reader:\n",
        "        \n",
        "            if i > 0:\n",
        "\n",
        "                entry = line.split(',')\n",
        "                annots.append(entry[1])\n",
        "                coords = map(float,entry[2:])\n",
        "                x_min, x_max, y_min, y_max = coords\n",
        "                x_min = x_min * W\n",
        "                x_max = x_max * W\n",
        "\n",
        "                y_min = y_min * H\n",
        "                y_max = y_max * H\n",
        "\n",
        "                boxes.append([x_min, y_min, x_max, y_max])\n",
        "            i = i + 1\n",
        "            \n",
        "        txt_reader.close()\n",
        "        boxes = torch.as_tensor(boxes, dtype=torch.float32)   \n",
        "        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])     \n",
        "        image_id = torch.tensor([idx])\n",
        "        \n",
        "        # As we consider only one class for detection\n",
        "        labels = torch.ones((boxes.shape[0],),dtype = torch.int64)\n",
        "        # None of the instances is crowd (interpret as 'background')\n",
        "        iscrowd = torch.zeros((boxes.shape[0],),dtype = torch.int64)\n",
        "\n",
        "        target = {}\n",
        "        target[\"boxes\"] = boxes\n",
        "        target[\"image_id\"] = image_id\n",
        "        target[\"labels\"] = labels\n",
        "        target[\"area\"] = area\n",
        "        target[\"iscrowd\"] = iscrowd\n",
        "        target[\"annots\"] = annots\n",
        "        \n",
        "        if self.transforms is not None:\n",
        "            img, target = self.transforms(img, target)\n",
        "\n",
        "        return img, target\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.imgs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CGkGTfeTiEIW"
      },
      "outputs": [],
      "source": [
        "class RetailDataset(Dataset):\n",
        "    def __init__(self,ref_img_list,transform=None):\n",
        "        self.transform = transform\n",
        "        self.img_list = ref_img_list\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.img_list[idx]\n",
        "        image = cv2.imread(img_path)\n",
        "        #image = load_tf_image(img_path)\n",
        "        if image is None:\n",
        "            print(img_path,idx,self.img_list[idx])\n",
        "        \n",
        "        image = cv2.resize(image,(224,224))\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        image = torch.from_numpy(image)\n",
        "        image = image.float() / 255\n",
        "        image = torch.permute(image,[2,0,1])\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FgYjL5Pcdu72"
      },
      "outputs": [],
      "source": [
        "ref_img_list = []\n",
        "for (root,dirs,files) in os.walk(\"/content/Grozi-3.2k-mine/Food\"):\n",
        "    for file in files:\n",
        "        ref_img_list.append(os.path.join(root,file))\n",
        "#print(ref_img_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mX1qQGcXwWHJ",
        "outputId": "a9b4c9ef-8d83-4cbb-b548-5a1bd3a2c166"
      },
      "outputs": [],
      "source": [
        "db = set([])\n",
        "for path in ref_img_list:\n",
        "    category = path[0:path.rindex('/')]\n",
        "    db.add(category)\n",
        "\n",
        "print(db)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EfR-lE5pyK15",
        "outputId": "4f534983-f7ca-4c87-a09f-c6da401e7198"
      },
      "outputs": [],
      "source": [
        "table = {}\n",
        "for (idx,entry) in enumerate(db):\n",
        "    table[entry]=idx\n",
        "print(table)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z7AJykjiflkF"
      },
      "outputs": [],
      "source": [
        "#files = sorted(os.listdir(\"/content/GP-180/train\"))\n",
        "#REF_DIR = \"/content/GP-180/train\"\n",
        "\n",
        "resnet18 = models.resnet18(pretrained = False)\n",
        "res18 = deepcopy(resnet18)\n",
        "\n",
        "path_to_embed_weights = \"/content/drive/MyDrive/ML_MODELS/resnet18_embed_gp_3.2k_ep6_OHNM.pt\"\n",
        "\n",
        "tsfm = transforms.Compose([transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])])\n",
        "stocks_ds = RetailDataset(ref_img_list,tsfm)\n",
        "stocks_dl = DataLoader(stocks_ds, batch_size = 128, shuffle = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8475R3Ym0ajz",
        "outputId": "f26554c2-d724-4c4a-b001-4b17b2165c29"
      },
      "outputs": [],
      "source": [
        "print(stocks_ds.img_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "id": "g3j-b-mDj5ck",
        "outputId": "0c7611ad-2c85-4442-c4f6-f6e48709877f"
      },
      "outputs": [],
      "source": [
        "ref_itr = iter(stocks_ds)\n",
        "img = next(ref_itr)\n",
        "display(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xAN40Z6yYvL_",
        "outputId": "e2dba44d-9c86-4448-b168-dab5657bd44c"
      },
      "outputs": [],
      "source": [
        "class ResNet18(nn.Module):\n",
        "    def __init__(self,FREEZE = False):\n",
        "        super(ResNet18,self).__init__()\n",
        "        self.entrypoint = nn.Sequential(res18.conv1,\n",
        "                                        res18.bn1,\n",
        "                                        res18.relu,\n",
        "                                        res18.maxpool)\n",
        "        #self.downConv = nn.MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
        "        self.layer1 = res18.layer1\n",
        "        self.layer2 = res18.layer2\n",
        "        self.layer3 = res18.layer3\n",
        "        self.layer4 = res18.layer4\n",
        "        self.maxpool_b3 = nn.MaxPool2d(kernel_size = (14,14))\n",
        "        self.maxpool_b4 = nn.MaxPool2d(kernel_size = (7,7))\n",
        "        #self.maxpool_b2 = nn.MaxPool2d(kernel_size = (28,28))\n",
        "        #self.fc1 = nn.Linear(in_features = 768,out_features = 1024, bias = True)\n",
        "\n",
        "        if FREEZE:\n",
        "            self.freeze_backbone()\n",
        "\n",
        "    def freeze_backbone(self):\n",
        "        self.entrypoint.requires_grad_(False)\n",
        "        self.layer1.requires_grad_(False)\n",
        "        self.layer2.requires_grad_(False)\n",
        "        self.layer3.requires_grad_(False)\n",
        "        #self.layer4.requires_grad_(False)\n",
        "\n",
        "    def forward(self,X):\n",
        "        X0 = self.entrypoint(X)\n",
        "        X1 = self.layer1(X0)\n",
        "        X2 = self.layer2(X1)\n",
        "        X3 = self.layer3(X2)\n",
        "        X4 = self.layer4(X3)\n",
        "        x3_flat = self.maxpool_b3(X3)\n",
        "        x4_flat = self.maxpool_b4(X4)\n",
        "        out = torch.cat([x3_flat,x4_flat],dim = 1)\n",
        "        out = out.view(X.shape[0],-1)\n",
        "        #out = self.fc1(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "encoder = ResNet18()\n",
        "\n",
        "chkpt = torch.load(path_to_embed_weights,map_location = GPU)\n",
        "encoder.load_state_dict(chkpt[\"model_state\"])\n",
        "encoder.to(GPU)\n",
        "print(\"Temporarily moved the encoder to GPU.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r_xZ7diRq_Iv"
      },
      "outputs": [],
      "source": [
        "#del encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "56bf1A_KhNIJ"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def extract_embeddings(dataloader, model, D):\n",
        "    model.eval()\n",
        "    embedder_dim = D\n",
        "\n",
        "    #with torch.no_grad():\n",
        "        \n",
        "    embeddings = torch.zeros((len(dataloader.dataset), embedder_dim)).to(GPU)\n",
        "\n",
        "    k = 0\n",
        "    for (nb,batch) in enumerate(tqdm(dataloader)):\n",
        "        batch = batch.to(GPU)\n",
        "        batch_size = batch.shape[0]\n",
        "        output = model(batch).view(batch_size,-1)\n",
        "        output = output / torch.linalg.norm(output,ord=2,dim =1,keepdim = True)\n",
        "        embeddings[k : k + batch_size] = output\n",
        "        k += batch_size\n",
        "\n",
        "    return embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F6WoaeCoq068"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vkv0Qa4npK64",
        "outputId": "671f9e7b-3088-4c55-9deb-3b0043180cbf"
      },
      "outputs": [],
      "source": [
        "embed_size = 768\n",
        "ref_embeddings = extract_embeddings(stocks_dl,encoder,embed_size)\n",
        "\n",
        "print(\"\\nShape of ref_embeddings is\",ref_embeddings.shape)\n",
        "print(\"Device of ref_embeddings\",ref_embeddings.device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZ82t8BPoSkD",
        "outputId": "ab08d120-3cdf-48c3-9da7-83d16c59d23f"
      },
      "outputs": [],
      "source": [
        "# ref_img_list = sorted(os.listdir(grozi_root))\n",
        "# print(ref_img_list)\n",
        "# print(len(ref_img_list))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rKUZxkQKpagu"
      },
      "outputs": [],
      "source": [
        "image_to_embed = {}\n",
        "for i in range(len(ref_img_list)):\n",
        "    image_to_embed[ref_img_list[i][:-4]] = ref_embeddings[i].cpu().tolist()\n",
        "\n",
        "#print(image_to_embed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DcmarvtxzFRo",
        "outputId": "500e1962-cf8d-4307-c9f7-5a5e5602996d"
      },
      "outputs": [],
      "source": [
        "#for key in image_to_embed.keys():\n",
        "#    print(key)\n",
        "print(image_to_embed[\"/content/Grozi-3.2k-mine/Food/Biscuits/25\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "98JqODIO1BYx"
      },
      "outputs": [],
      "source": [
        "with open(\"/content/drive/MyDrive/datasets/Grozi-3.2k-mine/embeddings.json\",'w') as fp:\n",
        "    json.dump(image_to_embed,fp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CuOoYFMY1b_J",
        "outputId": "06c2309c-1993-470e-a397-5b7905dbef32"
      },
      "outputs": [],
      "source": [
        "fin = open(\"/content/drive/MyDrive/datasets/Grozi-3.2k-mine/embeddings.json\")\n",
        "image_to_embed = json.load(fin)\n",
        "print(len(image_to_embed))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B5HjGvSo3zbz"
      },
      "outputs": [],
      "source": [
        "cluster_heads = {}\n",
        "for key in table.keys():\n",
        "    cluster_heads[key] = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q2SwNKClTpQr"
      },
      "outputs": [],
      "source": [
        "encodings = [x for x in image_to_embed.values()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TYnZjOx1O6Ll"
      },
      "outputs": [],
      "source": [
        "db_opt = OPTICS().fit(encodings)\n",
        "# core_samples_mask = np.zeros_like(dbs.labels_, dtype=bool)\n",
        "# core_samples_mask[dbs.core_sample_indices_] = True\n",
        "# labels = dbs.labels_\n",
        "\n",
        "# # Number of clusters in labels, ignoring noise if present.\n",
        "# n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
        "# n_noise_ = list(labels).count(-1)\n",
        "\n",
        "# print(f\"No. of clusters = {n_clusters_} and No. of noisy points : {n_noise_}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "purpg9-KVLNP",
        "outputId": "7464c11f-14c1-4871-993e-79f279b1f29e"
      },
      "outputs": [],
      "source": [
        "n_clusters = len(set(db_opt.labels_)) - (1 if -1 in db_opt.labels_ else 0)\n",
        "print(n_clusters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i0DZY_HI8IkZ"
      },
      "outputs": [],
      "source": [
        "class_focus = ['red','green','blue','orange','violet']\n",
        "class_focus.extend(['white' for y in range(22)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "INB1eB9O4N3d"
      },
      "outputs": [],
      "source": [
        "class_idx = []\n",
        "for path,embedding in image_to_embed.items():\n",
        "    category = path[:path.rindex('/')]\n",
        "    class_idx.append(table[category])\n",
        "    cluster_heads[category] = cluster_heads[category] + torch.FloatTensor(embedding)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ggx6aCtdzQw7",
        "outputId": "307319c5-205d-4e6e-898b-c41af2d6519a"
      },
      "outputs": [],
      "source": [
        "print(len(class_idx))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lAUi__fQ62sY"
      },
      "outputs": [],
      "source": [
        "for key in cluster_heads.keys():\n",
        "    cluster_heads[key] = cluster_heads[key]/torch.linalg.norm(cluster_heads[key],ord=2,dim =0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DidfDKY50Y2I",
        "outputId": "17ce568e-634e-4320-fca7-aa3f3b577a83"
      },
      "outputs": [],
      "source": [
        "encodings = torch.stack([torch.FloatTensor(value) for value in image_to_embed.values()])\n",
        "X = TSNE(n_components = 2 ,n_jobs = 4).fit_transform(encodings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2NS8DPVm5w_2"
      },
      "outputs": [],
      "source": [
        "class_reduce = []\n",
        "for x in class_idx:\n",
        "    if x < 5:\n",
        "        class_reduce.append(x)\n",
        "    else:\n",
        "        class_reduce.append(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A94jN-Qb8wJZ"
      },
      "outputs": [],
      "source": [
        "color_hash = [class_focus[table[key[0:key.rindex('/')]]] for key in image_to_embed.keys()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s1ZeE5N8-f2Y"
      },
      "outputs": [],
      "source": [
        "X_reduce = []\n",
        "hash_reduce = []\n",
        "for i in range(len(X)):\n",
        "    if color_hash[i] != 'white':\n",
        "        X_reduce.append(X[i])\n",
        "        hash_reduce.append(color_hash[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gzpU3BRNAuXA",
        "outputId": "bb1a99a6-8f18-4248-920c-a26a90e87e3b"
      },
      "outputs": [],
      "source": [
        "X_reduce = np.array(X_reduce)\n",
        "X_reduce.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 592
        },
        "id": "Y7pDLs5L2hgd",
        "outputId": "b803a612-d106-43da-8e09-b8d625bbcc06"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize = (12,10))\n",
        "plt.scatter(X_reduce[:,0],X_reduce[:,1],c = hash_reduce)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hUmufl8lLBTk"
      },
      "outputs": [],
      "source": [
        "pair_wise_similarity = torch.zeros(27,27)\n",
        "for (row,key1) in enumerate(cluster_heads.keys()):\n",
        "    for (col,key2) in enumerate(cluster_heads.keys()):\n",
        "        pair_wise_similarity[row][col] = 1 - torch.linalg.norm(cluster_heads[key1] - cluster_heads[key2],ord = 2,dim = 0)\n",
        "\n",
        "#print(pair_wise_similarity)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5JMOzIWRm8-e",
        "outputId": "b722c175-47ff-452d-a959-cd0bc5953859"
      },
      "outputs": [],
      "source": [
        "categories = [key[key.rindex('/') + 1:] for key in cluster_heads.keys()]\n",
        "categories[2] = 'DryFruits&Nuts'\n",
        "print(categories)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 948
        },
        "id": "yg6h85JNMSaP",
        "outputId": "4d9da130-78be-4115-eadb-c39eb56e769f"
      },
      "outputs": [],
      "source": [
        "#print(len(cluster_heads))\n",
        "plt.figure(figsize = (22,15))\n",
        "sbn.set(font_scale = 1.3)\n",
        "Ax = sbn.heatmap(pair_wise_similarity,center = 0.5,xticklabels = categories,yticklabels = categories,linewidths = 0.01)\n",
        "plt.xticks(rotation = 45)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U81CFX06rOah"
      },
      "outputs": [],
      "source": [
        "class UnNormalize(object):\n",
        "    def __init__(self, mean, std):\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "\n",
        "    def __call__(self, tensor):\n",
        "        for t, m, s in zip(tensor, self.mean, self.std):\n",
        "            t.mul_(s).add_(m)\n",
        "            # The normalize code -> t.sub_(m).div_(s)\n",
        "        return tensor\n",
        "\n",
        "def preprocess(image,transform = None):\n",
        "    if isinstance(image,torch.Tensor):\n",
        "        image = image.permute(1,2,0)\n",
        "        image = image.cpu().numpy()\n",
        "    image = cv2.resize(image,(224,224))\n",
        "    image = torch.from_numpy(image)\n",
        "    image = image.permute(2,0,1)\n",
        "    if transform:\n",
        "        image = transform(image)\n",
        "    return image\n",
        "\n",
        "def yield_top_k_matches(cropped_img, k = 5, apply_BRISK = False):\n",
        "    cropped_img = preprocess(cropped_img,tsfm).unsqueeze(dim = 0).to(GPU)\n",
        "    cropped_embed = encoder(cropped_img)\n",
        "    \n",
        "    cropped_repeat = torch.cat([cropped_embed for _ in range(len(stocks_ds))],dim = 0)\n",
        "    distances = torch.linalg.norm(cropped_repeat - ref_embeddings, dim = 1)\n",
        "    #assert distances.device == GPU\n",
        "    values,indices = distances.sort()\n",
        "\n",
        "    top_k = [stocks_ds.img_list[x][:-4] for x in indices[:k]] \n",
        "    return top_k"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "rhjddOw5xHoC",
        "outputId": "a97b8c23-290d-4794-84a7-ecbbbbf97709"
      },
      "outputs": [],
      "source": [
        "img = cv2.imread(\"/content/Grozi-3.2k-mine/Food/Drinks/Juices/137.jpg\")\n",
        "img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
        "img = cv2.resize(img,(410,410))\n",
        "img = img[40:230,30:240,:]\n",
        "img = img / 255.0\n",
        "plt.imshow(img)\n",
        "plt.show()\n",
        "img = torch.from_numpy(img).float()\n",
        "img = img.permute(2,0,1)\n",
        "#img = img.unsqueeze(dim = 0)\n",
        "#print(\"Shape of input image is \",img.shape)\n",
        "pred_cls = yield_top_k_matches(img,k = 5,apply_BRISK = False)\n",
        "print(pred_cls)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZEARO4B_ye0s"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 16\n",
        "#FINE_TUNE_PATH_TRAIN = \"/content/GP-total-finetune/train\"\n",
        "FINE_TUNE_PATH_TEST = \"/content/Grozi-3.2k-mine/Test/store1\"\n",
        "FINE_TUNE_PATH_VAL = \"/content/Grozi-3.2k-mine/Test/store1\"\n",
        "WORKERS_no = 2\n",
        "\n",
        "#train_ds = GroceryProducts(FINE_TUNE_PATH_TRAIN)\n",
        "valid_ds = GroceryProducts(FINE_TUNE_PATH_VAL)\n",
        "test_ds = GroceryProducts(FINE_TUNE_PATH_TEST)\n",
        "\n",
        "# train_dl = DataLoader(train_ds,\n",
        "#                       batch_size = BATCH_SIZE,\n",
        "#                       shuffle = True,\n",
        "#                       num_workers = WORKERS_no,\n",
        "#                       collate_fn = utils.collate_fn)\n",
        "\n",
        "valid_dl = DataLoader(valid_ds,\n",
        "                      batch_size = BATCH_SIZE,\n",
        "                      shuffle = False,\n",
        "                      num_workers = WORKERS_no // 2,\n",
        "                      collate_fn = utils.collate_fn)\n",
        "\n",
        "test_dl =  DataLoader(test_ds,\n",
        "                      batch_size = BATCH_SIZE,\n",
        "                      shuffle = False,\n",
        "                      num_workers = WORKERS_no //2\n",
        "                      ,collate_fn = utils.collate_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0YgJsS602Tan",
        "outputId": "4b699f04-a22b-42c6-cf12-45b841dccd13"
      },
      "outputs": [],
      "source": [
        "itr = iter(valid_ds)\n",
        "sample_img,sample_target = next(itr)\n",
        "plot_img_with_boxes(sample_img,sample_target[\"boxes\"])\n",
        "sample_img,sample_target = next(itr)\n",
        "plot_img_with_boxes(sample_img,sample_target[\"boxes\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YjNHjVMOyYlH"
      },
      "outputs": [],
      "source": [
        "def get_detection_model(num_classes,pre_trained = True):\n",
        "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=pre_trained)\n",
        "\n",
        "    # get number of input features for the classifier\n",
        "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "    \n",
        "    # replace the pre-trained head with a new one\n",
        "    model.roi_heads.box_predictor = faster_rcnn.FastRCNNPredictor(in_features, num_classes)\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L3hMrV7inhqY"
      },
      "outputs": [],
      "source": [
        "del model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LoNSFSipsEJz"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-FGDbPuw9OUe",
        "outputId": "fc58c016-daa6-4f0c-c46a-cbb6c9fe6666"
      },
      "outputs": [],
      "source": [
        "#!ls /content/Grozi-3.2k-mine/Test/store1/images | wc -l\n",
        "!ls /content/Grocery_products/Testing/store3/images | wc -l"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87,
          "referenced_widgets": [
            "35b44938e4e64f0a815dcb1cfcef91f8",
            "168d5489a2214c42af268f5b44cf7eaa",
            "3d7ac1a9108f4026b1cd6c39c3cace98",
            "1888020c03a1424ea3eace312ed685f7",
            "2c907225af354ebbbbdab9e13cbc8550",
            "c224fd85e7f940539a376f5ba2f30396",
            "331c4519d9d242569fb1c185013ddf15",
            "87f99345bb254136bcaf587305a858ff",
            "84a0c52c3faa4e72b6b4274e59bdd0f3",
            "f76f88f3233c45a9a794d3cbc410fd13",
            "fdec9c0379974c148cb7f8f9fedb4fda"
          ]
        },
        "id": "R2Y2oYlUdttm",
        "outputId": "d16ce6d1-0fe2-4e32-c262-178616e49936"
      },
      "outputs": [],
      "source": [
        "# our dataset has two classes only - b\n",
        "num_classes = 2\n",
        "\n",
        "# get the model using our helper function\n",
        "model = get_detection_model(num_classes,pre_trained = True)\n",
        "# move model to the right device\n",
        "#model.to(device)\n",
        "#print(\"model moved to device {0}\".format(device))\n",
        "#print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "di8fekQFw_T0"
      },
      "outputs": [],
      "source": [
        "model.rpn._pre_nms_top_n['training'] = 1000\n",
        "model.rpn._post_nms_top_n['training'] = 600\n",
        "model.rpn._pre_nms_top_n['testing'] = 500\n",
        "model.rpn._post_nms_top_n['testing'] = 50\n",
        "#model.roi_heads.nms_thresh = 0.30\n",
        "#model.roi_heads.score_thresh = 0.60"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MmoDggohcwY_"
      },
      "outputs": [],
      "source": [
        "model.to(GPU)\n",
        "pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85,
          "referenced_widgets": [
            "89f4c8824e424bf49fb7643ca681cb1d",
            "085f4e0f5db54078b688f206426f95cc",
            "dcba74ef0fb94c158ed2bc35aaaeec4e",
            "4ea1c53154be4bb1973acd3253e84464",
            "961e848cd4ac400db8c63a68b45d58e6",
            "9da10119cc6f4efcb60e0df677f820dc",
            "a8839e259f584f2786f4e9dfcf953d45",
            "b528529d047547be85a7c154d5cfb829",
            "482ef840e7cd45a2b2a19c62a24c3891",
            "0cbad17e9b0346ba9304aea4951a34d4",
            "b2142c3f71684e1fa170d7ae6900dd74"
          ]
        },
        "id": "sLezTTwimfQD",
        "outputId": "d26243e8-c1a6-4cd4-b681-83d468aa4ea3"
      },
      "outputs": [],
      "source": [
        "num_classes = 2\n",
        "model = get_detection_model(num_classes,pre_trained = False)\n",
        "ckpt = torch.load(\"/content/drive/MyDrive/ML_MODELS/faster_rcnn_res50_fpn_ft39(better-than-ft30).pt\",map_location = GPU)\n",
        "model.load_state_dict(ckpt[\"model\"])\n",
        "model.to(GPU)\n",
        "print(\"detector moved to gpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nzsBJkm7ZHKP"
      },
      "outputs": [],
      "source": [
        "#model.eval()\n",
        "model.rpn._pre_nms_top_n['testing'] = 500\n",
        "model.rpn._post_nms_top_n['testing'] = 30\n",
        "model.roi_heads.nms_thresh = 0.30                 # Margin for overlap between objects\n",
        "model.roi_heads.score_thresh = 0.60               # Confidence score of prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RT9ZkE9k38Nk",
        "outputId": "40b8fd8b-e9e1-4092-a63c-4a67f9f14528"
      },
      "outputs": [],
      "source": [
        "#for nbrs in range(5,31,5):\n",
        "#print(\"For {0} nearest neighbours\".format(nbrs))\n",
        "predictions,statistics,wrong_recogs,AP = validate_voc_format(model,valid_ds,top_k=20,threshold = 0.10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQvsKMc1XRVd",
        "outputId": "25812951-b15b-4b2d-bd73-bf464a031635"
      },
      "outputs": [],
      "source": [
        "AP_list = []\n",
        "for step in range(20):\n",
        "    pre_nms_candidates = 100 + 300 * step\n",
        "    model.rpn._pre_nms_top_n['testing'] = pre_nms_candidates\n",
        "    model.eval()\n",
        "    predictions,statistics,wrong_recogs,AP = validate_voc_format(model,valid_ds,top_k=20,threshold = 0.10)\n",
        "    AP_list.append(AP)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oiBEUDL9Es5W"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def test_inference_speed(model,eval_dataset,top_k = 5):\n",
        "    time_matrix = []\n",
        "    model.eval()\n",
        "    for step in range(20):\n",
        "        pre_nms_candidates = 100 + 300 * step\n",
        "        model.rpn._pre_nms_top_n['testing'] = pre_nms_candidates\n",
        "        time_matrix.append([])\n",
        "        for idx in tqdm(range(len(eval_dataset))):\n",
        "            #print(\"\\nprocessing item\",idx)\n",
        "            img_ts,target_ts = eval_dataset[idx]\n",
        "            img_ts = img_ts.to(GPU)\n",
        "\n",
        "            labels = target_ts[\"annots\"]\n",
        "            labels = [os.path.join(grozi_root,x[:-4]) for x in labels ]\n",
        "            #print(labels)\n",
        "            #labels = target_ts[\"labels\"]\n",
        "            \n",
        "            #uniq_labels = set(labels)\n",
        "            #pred_uniq_labels = set([])\n",
        "            t_start = time()\n",
        "            prediction_boxes = model([img_ts])[0][\"boxes\"].to(CPU)\n",
        "            n_boxes_pred = prediction_boxes.shape[0]\n",
        "\n",
        "            for i in range(len(prediction_boxes)):\n",
        "                x1,y1,x2,y2 = prediction_boxes[i]\n",
        "                x1,y1,x2,y2 = int(x1),int(y1),int(x2),int(y2)\n",
        "                \n",
        "                cropped = img_ts[:,y1:y2,x1:x2]\n",
        "                pcls = yield_top_k_matches(cropped,k = top_k,apply_BRISK = False)\n",
        "\n",
        "            t_end = time()\n",
        "            time_matrix[step].append(t_end - t_start)\n",
        "\n",
        "    return time_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FWJR65Z3L5H7",
        "outputId": "8e3ab330-484c-4261-a5b3-7cb2b1505f5a"
      },
      "outputs": [],
      "source": [
        "time_matrix = test_inference_speed(model,valid_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bikvMU_dND04",
        "outputId": "35628374-6441-49e5-9dae-0bf9486945f0"
      },
      "outputs": [],
      "source": [
        "time_matrix = torch.FloatTensor(time_matrix)\n",
        "print(time_matrix.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ojU_RizZT0YH",
        "outputId": "9795dd08-611b-4cf6-c2b7-e2ba0241416d"
      },
      "outputs": [],
      "source": [
        "time_means = time_matrix.mean(axis = 1)\n",
        "time_means.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iZ89dX8QSxBl",
        "outputId": "a980f660-4c5e-4727-ffa6-4cf40bb7a680"
      },
      "outputs": [],
      "source": [
        "region_proposals  = [100 + 300 * delta for delta in range(20)]\n",
        "print(region_proposals)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 501
        },
        "id": "qdpUWZH8TjMv",
        "outputId": "44d2a381-d21c-480e-bc63-b1110ce1c9b9"
      },
      "outputs": [],
      "source": [
        "sbn.set_style('darkgrid')\n",
        "plt.figure(figsize = (10,8))\n",
        "plt.plot(region_proposals,time_means * 1000,marker = '^')\n",
        "plt.ylim(400,500)\n",
        "plt.xlabel(\"No. of Region Proposals\")\n",
        "plt.ylabel(\"Inference Time (ms)\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ZByvA_s4nEF",
        "outputId": "ab585b64-aaee-4b3f-a833-aeb1a211daac"
      },
      "outputs": [],
      "source": [
        "print(stocks_ds.img_list[-13:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nL8R9inBEZoU",
        "outputId": "c58e9ef3-dee3-4ba8-f5fb-b7593378108f"
      },
      "outputs": [],
      "source": [
        "predictions = validate_ISI_format(model,valid_ds,top_k = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WfIiHYCN-zDo",
        "outputId": "b9bf40e3-b602-4189-f564-c589c9e3422e"
      },
      "outputs": [],
      "source": [
        "print(len(wrong_recogs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BJMfQfbR7faP"
      },
      "outputs": [],
      "source": [
        "def plot_predictions(wrong_preds):\n",
        "    for i in range(len(wrong_preds)):\n",
        "        gtruth = wrong_preds[i][1].cpu().permute(1,2,0).numpy()\n",
        "                \n",
        "        #gtruth = cv2.imread(os.path.join(_DIR,wrong_preds[i][0]))\n",
        "        \n",
        "        img1_path = os.path.join(REF_DIR,wrong_preds[i][2] + \".jpg\")\n",
        "        # print(img_path)\n",
        "        img1 = cv2.imread(img1_path)\n",
        "        #img2 = cv2.imread(os.path.join(ROOT_DIR,preds[i][1] + \".jpg\"))\n",
        "        #img3 = cv2.imread(os.path.join(ROOT_DIR,preds[i][2] + \".jpg\"))\n",
        "\n",
        "        #gtruth = cv2.cvtColor(gtruth,cv2.COLOR_BGR2RGB)\n",
        "        img1 = cv2.cvtColor(img1,cv2.COLOR_BGR2RGB)\n",
        "        #img2 = cv2.cvtColor(img2,cv2.COLOR_BGR2RGB)\n",
        "        #img3 = cv2.cvtColor(img3,cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        fig, axs = plt.subplots(1,2,figsize = (14,6))\n",
        "        axs[0].imshow(gtruth)\n",
        "        axs[0].set_title(wrong_recogs[i][0])\n",
        "\n",
        "        axs[1].imshow(img1)\n",
        "        axs[1].set_title(wrong_recogs[i][2])\n",
        "        \n",
        "        # axs[2].imshow(img2)\n",
        "        # axs[2].set_title(\"Top-2\")\n",
        "        # axs[3].imshow(img3)\n",
        "        # axs[3].set_title(\"Top-3\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "H7oFHkNl_DWM",
        "outputId": "bbb09529-9c81-43f8-8118-d8980df8e319"
      },
      "outputs": [],
      "source": [
        "plot_predictions(wrong_recogs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5FzGHmlbhW-",
        "outputId": "bb93cc7e-b236-4724-d2c2-6820e5f36c63"
      },
      "outputs": [],
      "source": [
        "verdicts = [stat[3] for stat in statistics]\n",
        "wrong_detections = 0\n",
        "\n",
        "for verdict in verdicts:\n",
        "    for x in verdict:\n",
        "        if x == -1:\n",
        "            wrong_detections += 1\n",
        "\n",
        "print(\"No. of Wrong detections!\",wrong_detections)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K3kB70l7TjQ3"
      },
      "outputs": [],
      "source": [
        "print(\"Mean IoU   Std. IoU\")\n",
        "for stat in statistics:\n",
        "    print(\"{0:.2f}        {1:.2f}\".format(stat[1].mean(),stat[1].std()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6oBDnbgiTcRA"
      },
      "outputs": [],
      "source": [
        "plot_pred_gt_side_by_side(valid_ds,predictions,judgements = verdicts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2wuRllHecFY3"
      },
      "outputs": [],
      "source": [
        "PATH = \"/content/drive/MyDrive/ML_MODELS\"\n",
        "torch.save({\"model\": model.state_dict(),\n",
        "            \"optimizer\": optimizer.state_dict(),\n",
        "            \"lr_scheduler\":lr_scheduler.state_dict(),\n",
        "            \"epochs\": num_epochs },os.path.join(PATH,\"faster_rcnn_res50_fpn_ft39(better-than-ft30).pt\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YHwIdxH76uPj"
      },
      "outputs": [],
      "source": [
        "# pick one image from the test set\n",
        "img, target = test_ds[0]\n",
        "\n",
        "model.rpn._post_nms_top_n[\"testing\"] = 50\n",
        "model.roi_heads.nms_thresh = 0.40\n",
        "\n",
        "# put the model in evaluation mode\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    prediction = model([img.to(device)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 594
        },
        "id": "VucHn_obXSXY",
        "outputId": "44a086a1-c61d-404b-86b5-469bc4ac19c8"
      },
      "outputs": [],
      "source": [
        "#display(img.permute(1,2,0).numpy())\n",
        "bboxes = prediction[0][\"boxes\"]\n",
        "gtboxes = target[\"boxes\"]\n",
        "image = img.permute(1,2,0).numpy()\n",
        "thickness = 2\n",
        "\n",
        "color1 = (255,0,0)\n",
        "color2 = (0,0,255)\n",
        "image1 = image.copy()\n",
        "image2 = image.copy()\n",
        "\n",
        "#plt.figure(figsize = (15,20))\n",
        "fig, axs = plt.subplots(1,2,figsize = (20,30),sharex = True)\n",
        "for i in range(bboxes.shape[0]):\n",
        "    start_pt = (int(bboxes[i][0]),int(bboxes[i][1]))\n",
        "    end_pt = (int(bboxes[i][2]),int(bboxes[i][3]))\n",
        "    image1 = cv2.rectangle(image1,start_pt,end_pt,color1,thickness)\n",
        "\n",
        "for i in range(gtboxes.shape[0]):\n",
        "    start_pt = (int(gtboxes[i][0]),int(gtboxes[i][1]))\n",
        "    end_pt = (int(gtboxes[i][2]),int(gtboxes[i][3]))\n",
        "    image2 = cv2.rectangle(image2,start_pt,end_pt,color2,thickness)\n",
        "\n",
        "axs[0].imshow(image1)\n",
        "axs[1].imshow(image2)\n",
        "\n",
        "plt.show()\n",
        "#plot_img_with_boxes(img.permute(1,2,0).numpy(),prediction[0][\"boxes\"])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "cv-retail-full-pipe-test.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "085f4e0f5db54078b688f206426f95cc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0cbad17e9b0346ba9304aea4951a34d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "168d5489a2214c42af268f5b44cf7eaa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1888020c03a1424ea3eace312ed685f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_84a0c52c3faa4e72b6b4274e59bdd0f3",
            "max": 167502836,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_87f99345bb254136bcaf587305a858ff",
            "value": 167502836
          }
        },
        "2c907225af354ebbbbdab9e13cbc8550": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fdec9c0379974c148cb7f8f9fedb4fda",
            "placeholder": "",
            "style": "IPY_MODEL_f76f88f3233c45a9a794d3cbc410fd13",
            "value": " 160M/160M [00:01&lt;00:00, 92.6MB/s]"
          }
        },
        "331c4519d9d242569fb1c185013ddf15": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35b44938e4e64f0a815dcb1cfcef91f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3d7ac1a9108f4026b1cd6c39c3cace98",
              "IPY_MODEL_1888020c03a1424ea3eace312ed685f7",
              "IPY_MODEL_2c907225af354ebbbbdab9e13cbc8550"
            ],
            "layout": "IPY_MODEL_168d5489a2214c42af268f5b44cf7eaa"
          }
        },
        "3d7ac1a9108f4026b1cd6c39c3cace98": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_331c4519d9d242569fb1c185013ddf15",
            "placeholder": "",
            "style": "IPY_MODEL_c224fd85e7f940539a376f5ba2f30396",
            "value": "100%"
          }
        },
        "482ef840e7cd45a2b2a19c62a24c3891": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ea1c53154be4bb1973acd3253e84464": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_482ef840e7cd45a2b2a19c62a24c3891",
            "max": 102530333,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b528529d047547be85a7c154d5cfb829",
            "value": 102530333
          }
        },
        "84a0c52c3faa4e72b6b4274e59bdd0f3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87f99345bb254136bcaf587305a858ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "89f4c8824e424bf49fb7643ca681cb1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dcba74ef0fb94c158ed2bc35aaaeec4e",
              "IPY_MODEL_4ea1c53154be4bb1973acd3253e84464",
              "IPY_MODEL_961e848cd4ac400db8c63a68b45d58e6"
            ],
            "layout": "IPY_MODEL_085f4e0f5db54078b688f206426f95cc"
          }
        },
        "961e848cd4ac400db8c63a68b45d58e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b2142c3f71684e1fa170d7ae6900dd74",
            "placeholder": "",
            "style": "IPY_MODEL_0cbad17e9b0346ba9304aea4951a34d4",
            "value": " 97.8M/97.8M [00:01&lt;00:00, 91.1MB/s]"
          }
        },
        "9da10119cc6f4efcb60e0df677f820dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a8839e259f584f2786f4e9dfcf953d45": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2142c3f71684e1fa170d7ae6900dd74": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b528529d047547be85a7c154d5cfb829": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c224fd85e7f940539a376f5ba2f30396": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dcba74ef0fb94c158ed2bc35aaaeec4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a8839e259f584f2786f4e9dfcf953d45",
            "placeholder": "",
            "style": "IPY_MODEL_9da10119cc6f4efcb60e0df677f820dc",
            "value": "100%"
          }
        },
        "f76f88f3233c45a9a794d3cbc410fd13": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fdec9c0379974c148cb7f8f9fedb4fda": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
